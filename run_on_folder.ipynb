{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fba72371",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from models import multiscale_model as multiscale\n",
    "from models import model\n",
    "from models import track_model\n",
    "from src.utils import visualize_detection_video, visualize_tracking_video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8f0be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "videos_folder = \"data/test_data/det_track/RGB/videos\"\n",
    "model_path = \"checkpoints/RGB/yolov8n2/best.pt\"\n",
    "output_folder = \"outputs/tunning\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ece7e9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "videos_path = [\n",
    "    os.path.join(videos_folder, video)\n",
    "    for video in os.listdir(videos_folder)\n",
    "    if video.endswith(('.mp4', '.avi', '.mov'))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1011c495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/test_data/det_track/IR/videos\\\\IR_BIRD_074.mp4',\n",
       " 'data/test_data/det_track/IR/videos\\\\IR_BIRD_075.mp4',\n",
       " 'data/test_data/det_track/IR/videos\\\\IR_BIRD_076.mp4',\n",
       " 'data/test_data/det_track/IR/videos\\\\IR_BIRD_077.mp4',\n",
       " 'data/test_data/det_track/IR/videos\\\\IR_BIRD_078.mp4',\n",
       " 'data/test_data/det_track/IR/videos\\\\IR_BIRD_079.mp4',\n",
       " 'data/test_data/det_track/IR/videos\\\\IR_DRONE_139.mp4',\n",
       " 'data/test_data/det_track/IR/videos\\\\IR_DRONE_142.mp4',\n",
       " 'data/test_data/det_track/IR/videos\\\\IR_DRONE_145.mp4',\n",
       " 'data/test_data/det_track/IR/videos\\\\IR_DRONE_147.mp4',\n",
       " 'data/test_data/det_track/IR/videos\\\\IR_DRONE_152.mp4',\n",
       " 'data/test_data/det_track/IR/videos\\\\IR_DRONE_155.mp4',\n",
       " 'data/test_data/det_track/IR/videos\\\\IR_DRONE_157.mp4']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "videos_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b44cd9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiscale_model = multiscale.DetectionModel(\n",
    "                model_path=model_path,\n",
    "                device=\"cuda\",\n",
    "            )\n",
    "yolo_model = model.DetectionModel(\n",
    "                model_path=model_path,\n",
    "                device=\"cuda\",\n",
    "            )\n",
    "track_model = track_model.TrackingModel(\n",
    "                multiscale_model\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6cd90220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with iou: 0.1, conf: 0.3\n",
      "Processing video: IR_BIRD_074\n",
      "Processing video: IR_BIRD_075\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing video: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvideo_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m output_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_folder\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/iou_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00miou\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_conf_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconf\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvideo_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 9\u001b[0m multiscale_det \u001b[38;5;241m=\u001b[39m \u001b[43mmultiscale_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvideo_detect\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mconf_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43miou_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43miou\u001b[49m\u001b[43m    \u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m yolo_det \u001b[38;5;241m=\u001b[39m yolo_model\u001b[38;5;241m.\u001b[39mvideo_detect(\n\u001b[0;32m     15\u001b[0m                                 path,\n\u001b[0;32m     16\u001b[0m                                 conf_threshold\u001b[38;5;241m=\u001b[39mconf,\n\u001b[0;32m     17\u001b[0m                                 iou_threshold\u001b[38;5;241m=\u001b[39miou\n\u001b[0;32m     18\u001b[0m                             )\n\u001b[0;32m     19\u001b[0m visualize_detection_video(\n\u001b[0;32m     20\u001b[0m     video_path\u001b[38;5;241m=\u001b[39mpath,\n\u001b[0;32m     21\u001b[0m     detection_frames\u001b[38;5;241m=\u001b[39myolo_det,\n\u001b[0;32m     22\u001b[0m     output_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/yolo.mp4\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     23\u001b[0m )\n",
      "File \u001b[1;32md:\\VGU_LAB\\vipcup2025\\models\\multiscale_model.py:249\u001b[0m, in \u001b[0;36mDetectionModel.video_detect\u001b[1;34m(self, video_path, scales, crop_ratio, weights, conf_threshold, iou_threshold)\u001b[0m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ret:\n\u001b[0;32m    247\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m--> 249\u001b[0m det \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage_detect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    250\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mscales\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscales\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    251\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mcrop_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcrop_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mconf_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconf_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m                        \u001b[49m\u001b[43miou_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43miou_threshold\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m                    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    257\u001b[0m frames\u001b[38;5;241m.\u001b[39mappend(det)\n\u001b[0;32m    258\u001b[0m \u001b[38;5;66;03m# if len(frames) >= 30:\u001b[39;00m\n\u001b[0;32m    259\u001b[0m \u001b[38;5;66;03m#     break\u001b[39;00m\n",
      "File \u001b[1;32md:\\VGU_LAB\\vipcup2025\\models\\multiscale_model.py:175\u001b[0m, in \u001b[0;36mDetectionModel.image_detect\u001b[1;34m(self, image, scales, crop_ratio, weights, conf_threshold, iou_threshold)\u001b[0m\n\u001b[0;32m    172\u001b[0m final_scores \u001b[38;5;241m=\u001b[39m wbf_scores[wbf_keep]\n\u001b[0;32m    173\u001b[0m final_labels \u001b[38;5;241m=\u001b[39m wbf_labels[wbf_keep]\n\u001b[1;32m--> 175\u001b[0m nms_keep_indices \u001b[38;5;241m=\u001b[39m \u001b[43mtorch_nms\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfinal_boxes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfinal_scores\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[43miou_threshold\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    180\u001b[0m final_boxes \u001b[38;5;241m=\u001b[39m [final_boxes[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m nms_keep_indices]\n\u001b[0;32m    181\u001b[0m final_scores \u001b[38;5;241m=\u001b[39m [final_scores[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m nms_keep_indices]\n",
      "File \u001b[1;32mc:\\Users\\phamd\\anaconda3\\envs\\env-3.9\\lib\\site-packages\\torchvision\\ops\\boxes.py:41\u001b[0m, in \u001b[0;36mnms\u001b[1;34m(boxes, scores, iou_threshold)\u001b[0m\n\u001b[0;32m     39\u001b[0m     _log_api_usage_once(nms)\n\u001b[0;32m     40\u001b[0m _assert_has_ops()\n\u001b[1;32m---> 41\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtorchvision\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnms\u001b[49m\u001b[43m(\u001b[49m\u001b[43mboxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscores\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miou_threshold\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\phamd\\anaconda3\\envs\\env-3.9\\lib\\site-packages\\torch\\_ops.py:1158\u001b[0m, in \u001b[0;36mOpOverloadPacket.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1156\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_torchbind_op_overload \u001b[38;5;129;01mand\u001b[39;00m _must_dispatch_in_python(args, kwargs):\n\u001b[0;32m   1157\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _call_overload_packet_from_python(\u001b[38;5;28mself\u001b[39m, args, kwargs)\n\u001b[1;32m-> 1158\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_op(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(kwargs \u001b[38;5;129;01mor\u001b[39;00m {}))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for iou in [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]:\n",
    "    for conf in [0.3, 0.4, 0.5, 0.6]:\n",
    "        print(f\"Running with iou: {iou}, conf: {conf}\")\n",
    "        for path in videos_path:\n",
    "            video_name = os.path.splitext(os.path.basename(path))[0]\n",
    "            print(f\"Processing video: {video_name}\")\n",
    "            output_path = f\"{output_folder}/iou_{iou}_conf_{conf}/{video_name}\"\n",
    "            \n",
    "            multiscale_det = multiscale_model.video_detect(\n",
    "                                                    path,\n",
    "                                                    conf_threshold=conf,\n",
    "                                                    iou_threshold=iou    \n",
    "                                                )\n",
    "            yolo_det = yolo_model.video_detect(\n",
    "                                            path,\n",
    "                                            conf_threshold=conf,\n",
    "                                            iou_threshold=iou\n",
    "                                        )\n",
    "            visualize_detection_video(\n",
    "                video_path=path,\n",
    "                detection_frames=yolo_det,\n",
    "                output_path=f\"{output_path}/yolo.mp4\"\n",
    "            )\n",
    "            visualize_detection_video(\n",
    "                video_path=path,\n",
    "                detection_frames=multiscale_det,\n",
    "                output_path=f\"{output_path}/multiscale.mp4\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0bb0a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# yolo_model = model.DetectionModel(\n",
    "#                             model_path,\n",
    "#                             conf_threshold=0.3,\n",
    "#                             iou_threshold=0.45\n",
    "#                             )\n",
    "# multiscale_model = multiscale.DetectionModel(\n",
    "#                                     model_path,\n",
    "#                                     conf_threshold=0.3,\n",
    "#                                     iou_threshold=0.1\n",
    "#                                     )\n",
    "# yolo_track_model = track_model.TrackingModel(\n",
    "#                             yolo_model,\n",
    "#                             )\n",
    "# multiscale_track_model = track_model.TrackingModel(\n",
    "#                             multiscale_model,\n",
    "#                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58ced23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for path in videos_path:\n",
    "#     video_name = os.path.basename(path).removesuffix('.mp4').removesuffix('.avi').removesuffix('.mov')\n",
    "#     print(f\"Processing video: {video_name}\")\n",
    "    \n",
    "#     # # Detection\n",
    "#     yolo_det = yolo_model.video_detect(path)\n",
    "#     multiscale_det = multiscale_model.video_detect(path)\n",
    "    \n",
    "#     visualize_detection_video(\n",
    "#         video_path=path,\n",
    "#         detection_frames=yolo_det,\n",
    "#         output_path=f\"{output_folder}/detection/{video_name}/yolo.mp4\"\n",
    "#     )\n",
    "#     visualize_detection_video(\n",
    "#         video_path=path,\n",
    "#         detection_frames=multiscale_det,\n",
    "#         output_path=f\"{output_folder}/detection/{video_name}/multiscale.mp4\"\n",
    "#     )\n",
    "    \n",
    "#     # # Tracking\n",
    "#     yolo_track = yolo_track_model.video_track(path)\n",
    "#     multiscale_track = multiscale_track_model.video_track(path)\n",
    "#     visualize_tracking_video(\n",
    "#         video_path=path,\n",
    "#         tracking_frames=yolo_track,\n",
    "#         output_path=f\"{output_folder}/tracking/{video_name}/yolo.mp4\"\n",
    "#     )\n",
    "#     visualize_tracking_video(\n",
    "#         video_path=path,\n",
    "#         tracking_frames=multiscale_track,\n",
    "#         output_path=f\"{output_folder}/tracking/{video_name}/multiscale.mp4\"\n",
    "#     )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
