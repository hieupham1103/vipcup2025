{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b432fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from utils.multiscale import YOLOMS\n",
    "from utils.evaluate import evaluate\n",
    "import os\n",
    "\n",
    "class_names = [\"BIRD\", \"DRONE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bd89af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_detections(img, boxes, labels, scores, title):\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    fig, ax = plt.subplots(1)\n",
    "    ax.imshow(img_rgb)\n",
    "    ax.set_title(title)\n",
    "    ax.axis('off')\n",
    "\n",
    "    for box, label, score in zip(boxes, labels, scores):\n",
    "        x1, y1, x2, y2 = box\n",
    "        width = x2 - x1\n",
    "        height = y2 - y1\n",
    "        rect = patches.Rectangle((x1, y1), width, height, linewidth=2,\n",
    "                                 edgecolor='lime', facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "        ax.text(x1, y1 - 5, f'{label} - {score:.2f}', color='yellow', fontsize=8,\n",
    "                bbox=dict(facecolor='black', alpha=0.5, pad=1, edgecolor='none'))\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ace2a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_yolo_annotation(txt_path, img_shape):\n",
    "    h, w = img_shape[:2]\n",
    "    boxes = []\n",
    "    labels = []\n",
    "    with open(txt_path, 'r') as f:\n",
    "        for line in f:\n",
    "            class_id, xc, yc, bw, bh = map(float, line.strip().split())\n",
    "            x1 = (xc - bw / 2) * w\n",
    "            y1 = (yc - bh / 2) * h\n",
    "            x2 = (xc + bw / 2) * w\n",
    "            y2 = (yc + bh / 2) * h\n",
    "            boxes.append([x1, y1, x2, y2])\n",
    "            labels.append(int(class_id))\n",
    "\n",
    "    return boxes, labels\n",
    "\n",
    "def ground_truth_detections(img, txt_path):\n",
    "    gt_boxes, gt_labels = read_yolo_annotation(txt_path, img.shape)\n",
    "    label_strs = [class_names[l] for l in gt_labels]\n",
    "    scores = [1.0] * len(gt_boxes)\n",
    "\n",
    "    plot_detections(img.copy(), gt_boxes, label_strs, scores, \"Ground Truth\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5078bf4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_detections(img, model):\n",
    "    res = model.predict(img,\n",
    "                        imgsz=[320, 256],\n",
    "                        device=1,\n",
    "                        verbose=False)[0]\n",
    "    boxes_yolo = res.boxes.xyxy.cpu().numpy()\n",
    "    labels_yolo = res.boxes.cls.cpu().numpy().astype(int)\n",
    "    scores_yolo = res.boxes.conf.cpu().numpy()\n",
    "    \n",
    "    label_strs = [class_names[l] for l in labels_yolo]\n",
    "\n",
    "    plot_detections(img.copy(), boxes_yolo, label_strs, scores_yolo, \"YOLOv8n Original (NMS)\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94cbe17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_multiscale_detections(img, model):\n",
    "    boxes_yolo_wbf, scores_yolo_wbf, labels_yolo_wbf = model.detect(img, device=1)\n",
    "    # print(f\"YOLOv8n Multiscale: {len(boxes_yolo_wbf)} detections\")\n",
    "    # print(f\"Boxes: {boxes_yolo_wbf}\")\n",
    "    # print(f\"Scores: {scores_yolo_wbf}\")\n",
    "    # print(f\"Labels: {labels_yolo_wbf}\")\n",
    "    label_strs = [class_names[int(l)] for l in labels_yolo_wbf]\n",
    "    plot_detections(img.copy(), boxes_yolo_wbf, label_strs, scores_yolo_wbf, \"YOLOv8n Multiscale\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb06480",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_images(txt_file: str):\n",
    "    paths = []\n",
    "    with open(txt_file, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line or line.startswith('#'):\n",
    "                continue\n",
    "            paths.append(line)\n",
    "    return paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afbaca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_model = YOLO(\"/home/cvpr2025/yolo_testing/runs/detect/train/weights/best.pt\")\n",
    "multi_scale_model = YOLOMS(yolo_model,\n",
    "                           segment_ratio = 0.7,\n",
    "                           iou_thr = 0.5,\n",
    "                           conf_thr = 0.5,\n",
    "                           weight = [1, 2]\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e531128a",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_paths = list_images(\"/home/cvpr2025/yolo_testing/config/Detection/RGB/test.txt\")\n",
    "\n",
    "img_name = \"BIRD_02079_103\"\n",
    "img = cv2.imread(f\"/home/cvpr2025/yolo_testing/data/vipcup_det/split_A/RGB/images/test/{img_name}.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef19fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ground_truth_detections(img, f\"/home/cvpr2025/yolo_testing/data/vipcup_det/split_A/RGB/labels/test/{img_name}.txt\")\n",
    "# yolo_detections(img, model=yolo_model)\n",
    "# yolo_multiscale_detections(img, model=multi_scale_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabc2612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# res = yolo_model.val(data=\"/home/cvpr2025/yolo_testing/config/Detection/RGB/vipcup_det_A_RGB.yml\", split=\"test\", device=1, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12995f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE = '/home/cvpr2025/yolo_testing/data/vipcup_det/split_A/RGB'\n",
    "IMAGE_FOLDER = os.path.join(BASE, 'images', 'test')\n",
    "GT_JSON = '/home/cvpr2025/yolo_testing/data/vipcup_det/split_A/RGB/gt_test.json'\n",
    "CLASS_NAMES = ['BIRD', 'DRONE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a2b04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"=== Evaluate YOLOv8\")\n",
    "# res_yolo = evaluate(yolo_model, GT_JSON, IMAGE_FOLDER, device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a55786",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Evaluate YOLOv8n Multiscale ===\")\n",
    "res_yolo_multiscale = evaluate(multi_scale_model, GT_JSON, IMAGE_FOLDER, device=\"cpu\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
